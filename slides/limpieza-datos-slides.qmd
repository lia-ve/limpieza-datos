---
title: "Preprocesamiento y limpieza de datos"
subtitle: "Domesticando datos en estado salvaje"
lang: es
author:
  - name: Francisco Palm
    orcid: 0000-0002-1293-0868
    email: fpalm@lia-ve.org
    affiliations: Laboratorio Venezolano de Inteligencia Artificial
format:
  revealjs: 
    theme: [default, custom.scss]
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: images/logo_lia.png
    footer: '[Laboratorio Venezolano de Inteligencia Artificial](https://www.lia-ve.org)'
---

## Introducción

En esta sesión, aprenderás los pasos fundamentales para el preprocesamiento y limpieza de datos, conocidos también como el análisis inicial de datos.

Nos enfocaremos en entender el **contenido**, la **estructura** y la **coherencia** de los datos, identificar problemas potenciales, y realizar las transformaciones necesarias para asegurarnos de que los datos estén en condiciones óptimas para un análisis más avanzado.

## Objetivos:

1.  Entender que son datos ordenados y su importancia.

2.  Modificar estructura y contenido para obtener datos ordenados.

3.  Identificar y manejar valores faltantes y atípicos.

4.  Establecer las bases para una adecuada limpieza y transformación de datos.

5.  Preparar los datos para el análisis exploratorio de datos (AED).

## Análisis inicial de datos

El análisis inicial de datos es la fase en la que se inspeccionan los datos **crudos** para entender su **estructura**, **calidad** y **contenido** antes de realizar un análisis más profundo.

Esta fase incluye:

-   La revisión de la forma general del conjunto de datos.

-   La identificación de posibles problemas (valores faltantes, duplicados, valores atípicos, inconsistencias).

-   La preparación de los datos para su uso en el análisis exploratorio y modelado.

## Ejemplo de análisis inicial

``` python
import pandas as pd

# Cargar un conjunto de datos
df = pd.read_csv('datos.csv')

# Ver un resumen de los tipos de datos y el número de valores no nulos
print(df.info())

# Ver las primeras filas del conjunto de datos
print(df.head())

# Ver un resumen estadístico del conjunto de datos
print(df.describe())

# Verificar valores faltantes
print(df.isnull().sum())

# Verificar duplicados
print(df.duplicated().sum())

# Identificar valores atípicos usando el método IQR (Interquartile Range)
Q1 = df['variable'].quantile(0.25)
Q3 = df['variable'].quantile(0.75)
IQR = Q3 - Q1
outliers = df[(df['variable'] < (Q1 - 1.5 * IQR)) | (df['variable'] > (Q3 + 1.5 * IQR))]
print(outliers)
```

## Ejemplo de Análisis Exploratorio de Datos (AED):

``` python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar un conjunto de datos
df = pd.read_csv('datos.csv')

# Visualizar la distribución de una variable
sns.histplot(df['variable'], kde=True)
plt.title('Distribución de la variable')
plt.show()

# Visualizar la relación entre dos variables
sns.scatterplot(x='variable1', y='variable2', data=df)
plt.title('Relación entre variable1 y variable2')
plt.show()

# Visualizar la correlación entre variables
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Matriz de correlación')
plt.show()

# Realizar un análisis de componentes principales (PCA)
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
principal_components = pca.fit_transform(df)
principal_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])

# Visualizar los componentes principales
sns.scatterplot(x='PC1', y='PC2', data=principal_df)
plt.title('Componentes principales')
plt.show()
```

## Datos sucios

Conjuntos de información que presentan deficiencias, anomalías o inconsistencias que comprometen su calidad y fiabilidad para el análisis y la toma de decisiones.

Identificar y "limpiar" datos sucios es una fase crucial en cualquier proyecto de análisis de datos, ya que la calidad de los resultados depende directamente de la calidad de los datos de entrada. Como se dice comúnmente: *Garbage in, garbage out* (si entra basura, sale basura).

## ¿Qué problemas tienen estos datos?

```{python}
import pandas as pd
import numpy as np
```

```{python}
df = pd.read_csv("data/studentmockup.csv")
df
```

## Dimensiones de la calidad de los datos {.smaller}

::::: columns
::: {.column width="50%"}
-   **Exactitud**: Grado en que los datos representan correctamente la realidad que describen.

-   **Completitud**: Presencia de todos los valores necesarios sin elementos faltantes.

-   **Consistencia**: Coherencia entre datos relacionados y cumplimiento de reglas de negocio.

-   **Uniformidad**: Estandarización en la representación de los datos.

-   **Validez**: Conformidad con las restricciones y tipos de datos definidos.
:::

::: {.column width="50%"}
-   **Temporalidad**: Vigencia y actualización oportuna de la información.

-   **Unicidad**: Ausencia de duplicados innecesarios.

-   **Integridad**: Mantenimiento de las relaciones entre conjuntos de datos.

-   **Precisión**: Nivel de detalle y exactitud en la medición de los valores.

-   **Relevancia**: Utilidad y pertinencia de los datos para su propósito previsto.
:::
:::::

## Factores de evaluación

-   Calidad del ***contenido***

    -   Calidad de los ***valores***

    -   Calidad de los ***formatos***

-   Calidad de la ***estructura***

-   Calidad de ***coherencia***

    -   Calidad de ***consistencia***

    -   Calidad de ***integración***

## Transformaciones a los datos (para limpiar)

-   Realizar cambios de formato y estructura para que se ajusten a las necesidades de análisis y visualización.

-   Aplicar operaciones básicas: filtros, consultas, selección de variables, creación de nuevas variables a partir de las actuales, agrupar valores por unas variables y agregar los valores de las restantes.

-   Adaptar formatos especiales como fechas o geolocalización.

# Estructura {background-color="#986EFF"}

## Problemas estructurales

-   Demasiados campos: frecuentemente ocurre con redundancias, o con datos que se pueden concatenar en un solo campo (líneas de dirección, por ejemplo).

-   Campos faltantes, que quizás se pueden extrapolar de otros campos existentes.

-   Falta de correspondencia entre valores y campos.

-   Campos mal definidos, quizás con algún problema en el tipo de valor que se utiliza.

## Conjunto de Datos *Air Quality*

<https://archive.ics.uci.edu/dataset/360/air+quality>

Leamos con cuidado la documentación:

-   Cuenta con $5$ variables y $9358$ observaciones.

-   Los valores faltantes están marcados con $-200$.